{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMVqUPwoWLMnNKIxczgf7b1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shivani-202/CS-Deep-Learning-Assignment/blob/main/activation_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examine the performance of various activation functions for MNIST, Fashion-MNIST, CIFAR-10, and CIFAR-100.\n",
        "For training,  use the architectures ResNet, LeNet, MobileNet, AlexNet, with different learnable depths."
      ],
      "metadata": {
        "id": "wyS1apgdKdbb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F3zMJA9HdoG",
        "outputId": "e008b7b4-ef03-497c-9eb6-aea88d61c843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training with SIGMOID on MNIST using get_resnet_model model...\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 10.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 349kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.20MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 111] Connection refused>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.15MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 109MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision.models as models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Activation function mapping\n",
        "def activation_func(name, param=0.01):\n",
        "    activation = {\n",
        "        \"sigmoid\": nn.Sigmoid(),\n",
        "        \"bipolar_sigmoid\": lambda x: 2 * torch.sigmoid(x) - 1,\n",
        "        \"tanh\": nn.Tanh(),\n",
        "        \"relu\": nn.ReLU(),\n",
        "        \"leaky_relu\": nn.LeakyReLU(param),\n",
        "        \"param_relu\": nn.PReLU(),\n",
        "        \"elu\": nn.ELU(param),\n",
        "        \"softmax\": nn.Softmax(dim=1),\n",
        "        \"gelu\": nn.GELU(),\n",
        "        \"selu\": nn.SELU(),\n",
        "        \"mish\": nn.Mish(),\n",
        "        \"softplus\": nn.Softplus(),\n",
        "        \"swish\": nn.SiLU(),\n",
        "        \"e_swish\": lambda x: 1.5 * x * torch.sigmoid(x),\n",
        "        \"telu\": nn.CELU(param),\n",
        "    }\n",
        "    return activation[name]\n",
        "\n",
        "\n",
        "def get_resnet_model(activation, num_classes=10, input_channels=3):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.conv1 = nn.Conv2d(input_channels, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    model.layer1[0].relu = activation_func(activation)\n",
        "    model.layer2[0].relu = activation_func(activation)\n",
        "    model.layer3[0].relu = activation_func(activation)\n",
        "    model.layer4[0].relu = activation_func(activation)\n",
        "    return model\n",
        "\n",
        "def get_alexnet_model(activation, num_classes=10, input_channels=3):\n",
        "    model = models.alexnet(pretrained=True)\n",
        "    model.features[0] = nn.Conv2d(input_channels, 64, kernel_size=11, stride=4, padding=2)\n",
        "    model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "    model.classifier[4] = activation_func(activation)\n",
        "    return model\n",
        "\n",
        "def get_mobilenet_model(activation, num_classes=10, input_channels=3):\n",
        "    model = models.mobilenet_v2(pretrained=True)\n",
        "    model.features[0][0] = nn.Conv2d(input_channels, 32, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "    model.features[0][0].relu = activation_func(activation)\n",
        "    return model\n",
        "\n",
        "# Get dataloaders for datasets\n",
        "def get_dataloader(dataset_name, batch_size=64):\n",
        "    if dataset_name == \"mnist\":\n",
        "        transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "        trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    elif dataset_name == \"cifar10\":\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "        testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "    elif dataset_name == \"fashion-mnist\":\n",
        "        transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "        trainset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "        testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "    elif dataset_name == \"cifar100\":\n",
        "        transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "        trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "    return trainloader, testloader\n",
        "\n",
        "# Training function\n",
        "def train(model, trainloader, testloader, criterion, optimizer, writer, num_epochs=10, dataset_name=\"Dataset\"):\n",
        "    model.train()\n",
        "    all_loss, all_acc = [], []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        all_preds, all_labels = [], []\n",
        "        epoch_loss = 0\n",
        "        for i, (images, labels) in enumerate(trainloader):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "        epoch_loss /= len(trainloader)\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        all_loss.append(epoch_loss)\n",
        "        all_acc.append(acc)\n",
        "\n",
        "        writer.add_scalar(f\"Loss/{dataset_name}\", epoch_loss, epoch)\n",
        "        writer.add_scalar(f\"Accuracy/{dataset_name}\", acc, epoch)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] - Loss: {epoch_loss:.4f} | Accuracy: {acc:.4f}\")\n",
        "\n",
        "    return all_loss, all_acc\n",
        "\n",
        "\n",
        "def plot_performance(activation_names, all_loss, all_acc):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot loss for all activation functions\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for i, loss in enumerate(all_loss):\n",
        "        plt.plot(loss, label=activation_names[i])\n",
        "    plt.title('Loss for different Activation Functions')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy for all activation functions\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for i, acc in enumerate(all_acc):\n",
        "        plt.plot(acc, label=activation_names[i])\n",
        "    plt.title('Accuracy for different Activation Functions')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Main script\n",
        "if __name__ == \"__main__\":\n",
        "    writer = SummaryWriter(\"runs/activation_experiment\")\n",
        "    datasets = [\"mnist\", \"fashion-mnist\", \"cifar10\", \"cifar100\"]\n",
        "    activation_functions = [\"sigmoid\", \"relu\", \"tanh\", \"leaky_relu\", \"elu\", \"softmax\", \"gelu\", \"selu\", \"mish\", \"swish\", \"bipolar_sigmoid\", \"e_swish\", \"param_relu\", \"telu\", \"softplus\"]\n",
        "\n",
        "    models_to_train = [get_resnet_model, get_alexnet_model, get_mobilenet_model]\n",
        "\n",
        "    all_loss = []\n",
        "    all_acc = []\n",
        "    activation_names = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        for activation in activation_functions:\n",
        "            for model_fn in models_to_train:\n",
        "                print(f\"\\nTraining with {activation.upper()} on {dataset.upper()} using {model_fn.__name__} model...\")\n",
        "                trainloader, testloader = get_dataloader(dataset)\n",
        "\n",
        "                input_channels = 1 if dataset in [\"mnist\", \"fashion-mnist\"] else 3\n",
        "                model = model_fn(activation, num_classes=10 if dataset != \"cifar100\" else 100, input_channels=input_channels)\n",
        "\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "                loss, acc = train(model, trainloader, testloader, criterion, optimizer, writer, num_epochs=10, dataset_name=dataset)\n",
        "                all_loss.append(loss)\n",
        "                all_acc.append(acc)\n",
        "                activation_names.append(f\"{activation}_{model_fn.__name__}\")\n",
        "\n",
        "    writer.close()\n",
        "    plot_performance(activation_names, all_loss, all_acc)\n"
      ]
    }
  ]
}